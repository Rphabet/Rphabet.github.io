---
title: TensorFlowë¥¼ ì´ìš©í•œ ë‹¤ì¤‘ì„ í˜•íšŒê·€ë¶„ì„
date: 2021-09-03 19:52:00 +0900
categories: [python, regression]
tags: [python, regression, íšŒê·€ë¶„ì„, ML, ë¨¸ì‹ ëŸ¬ë‹, tensorflow, í…ì„œí”Œë¡œìš°] 
math: true
comments: true
image:
  src: /../assets/images/tf/logo.png
  width: 500
  height: 200
  alt: tensorflow logo
typora-root-url: ../

---

---

# Multiple Linear Regression Using TensorFlow

ì§€ë‚œ í¬ìŠ¤íŒ…ì—ì„œ ë‹¨ì¼ ë³€ìˆ˜ë¥¼ ê°–ê³  `sklearn` ë¼ì´ë¸ŒëŸ¬ë¦¬ì™€ ê¸°ë³¸ íŒŒì´ì¬ì„ ì´ìš©í•´ì„œ ì„ í˜•íšŒê·€ë¶„ì„ì„ í•´ë³´ì•˜ë‹¤([ë§í¬](https://rphabet.github.io/posts/ML_reg_data_handling/)). 

ì´ë²ˆ í¬ìŠ¤íŒ…ì—ì„  ë…ë¦½ ë³€ìˆ˜ ë‘ê°œë¥¼ ë” ì¶”ê°€í•´ì„œ ì´ 3ê°œì˜ ë…ë¦½ë³€ìˆ˜ë¥¼ ê°–ê³  ì§„í–‰í•´ë³´ë„ë¡ í•˜ì.

$$ \hat{y} = \beta_0 + \beta_1x_1 + \beta_2x_2 + \beta_3x_3 $$

ê·¸ë¦¬ê³  ì´ì   `tensorflow`ë¼ì´ë¸ŒëŸ¬ë¦¬ë„ ê°™ì´ í™œìš©ì„ í•  ì˜ˆì •ì´ë‹ˆ ì°¸ê³ í•˜ê¸¸ ë°”ë€ë‹¤.

ê¸°ë³¸ì ì¸ ë°ì´í„° êµ¬ì„±ì„ ì‚´í´ë³´ìë©´...

|x1|x2|x3|t|
|---|---|---|---|
|30|70|90|180|
|70|80|70|177|
|90|100|80|198|
|30|50|20|105|

ì´ë ‡ê²Œ ë„¤ê°œì˜ ë³€ìˆ˜ë¡œ training data setì´ êµ¬ì„±ë˜ì–´ ìˆë‹¤.

x1, x2, x3ëŠ” ë…ë¦½ë³€ìˆ˜, tëŠ” ì¢…ì†ë³€ìˆ˜ë¥¼ ë‚˜íƒ€ë‚¸ë‹¤. 

ì´ë ‡ê²Œ ìƒê¸´ ë°ì´í„° ì…‹ì„ ê°–ê³  íšŒê·€ë¶„ì„ì„ í•˜ê²Œ ëœë‹¤ë©´ ë‹¤ì¤‘íšŒê·€ë¶„ì„ì„ í•˜ê²Œ ë˜ëŠ”ê±°ë‹¤.

ë°”ë¡œ ì˜ˆì œë¡œ ë“¤ì–´ê°€ë³´ì.

```python
# í•„ìš” íŒ¨í‚¤ì§€ ë¡œë”©
# set environment
import numpy as np
import pandas as pd
import tensorflow as tf
import matplotlib.pyplot as plt
from scipy import stats  # zscore
from sklearn import linear_model # sklearnìœ¼ë¡œë„ ëª¨ë¸ ìƒì„±, í•™ìŠµ, ì˜ˆì¸¡
from sklearn.preprocessing import MinMaxScaler  # normalisation
```

ë°ì´í„° ë¡œë”© ë° ì´ìƒì¹˜ ê²°ì¹˜ ì²˜ë¦¬ë¥¼ ìœ„í•œ ì½”ë“œ: 

( `ozone.csv` íŒŒì¼ì€ ì¶”í›„  ê¹ƒí—™ì— ì˜¬ë ¤ë‘ê² ë‹¤. (ë§í¬) )

```python
# Raw Data Loading
df = pd.read_csv('./data/ozone/ozone.csv', sep=',')
training_data_set = df[['Solar.R', 'Wind', 'Temp', 'Ozone']]

# 1. ê²°ì¹˜ê°’ ì²˜ë¦¬
training_data = training_data_set.dropna(how='any')  # NaNí–‰ ì‚­ì œ
# display(training_data.shape) # (111, 4)

# 2. ì´ìƒì¹˜ ì²˜ë¦¬
zscore_threshold = 1.8
outlier = training_data['Ozone'][ np.abs(stats.zscore(training_data['Ozone'])) > zscore_threshold ]
training_data = training_data.loc[ ~training_data['Ozone'].isin(outlier), :] # 103 rows Ã— 2 columns

# 3. ì •ê·œí™” ì²˜ë¦¬
# scaling ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ê°ì²´ë¥¼ í•˜ë‚˜ ìƒì„± (ì…ë ¥ê°’ ì²˜ë¦¬ í•˜ëŠ”ë†ˆ 1ê°œ, label ì²˜ë¦¬ í•˜ëŠ” ë†ˆ 1ê°œ)
scaler_x = MinMaxScaler()
scaler_y = MinMaxScaler()

scaler_x.fit(training_data.iloc[:, :-1].values)  # training_data.loc[:, 'Solar.R':'Temp'].values
# ê°ê° xì— ëŒ€í•œ ìŠ¤ì¼€ì¼ëŸ¬ê°€ ë‹¤ í•„ìš”í•œê²Œ ì•„ë‹˜.
# xì „ì²´ì— ëŒ€í•œ í•˜ë‚˜ì˜ scalerë©´ ì¶©ë¶„í•¨ (n x 3) í–‰ë ¬ë¡œ ì²˜ë¦¬í•˜ê¸°ë•Œë¬¸.
scaler_y.fit(training_data['Ozone'].values.reshape(-1,1))

training_data.iloc[:, :-1] = scaler_x.transform(training_data.iloc[:, :-1].values) 
# training data setì˜ xì˜ ê°’ë“¤ì„ ì •ê·œí™”ëœ ê°’ìœ¼ë¡œ ì±„ì›Œ ë„£ëŠ” ì½”ë“œì„
training_data['Ozone'] = scaler_y.transform(training_data['Ozone'].values.reshape(-1,1))
# ë§ˆì°¬ê°€ì§€ë¡œ labelì„ ì •ê·œí™”ëœ ê°’ìœ¼ë¡œ ì±„ì›Œ ë„£ëŠ” ì½”ë“œ.

display(training_data) # ì´ë ‡ê²Œ dataframeì„ ì¶œë ¥í•´ë³´ë©´ ê°’ë“¤ì´ 0~1ì‚¬ì´ë¡œ ë–¨ì–´ì§„ê±¸ ë³¼ ìˆ˜ ìˆë‹¤.

# 4. Training Data Set

x_data = training_data.iloc[:, :-1].values
t_data = training_data['Ozone'].values.reshape(-1, 1)
```

ì´ì œ `tensorflow`ë¡œ ê·¸ë˜í”„ë¥¼ ê·¸ë¦¬ê³  ì‹¤í–‰ì‹œì¼œë³´ì.

- training data setì„ ë°›ì•„ë“¤ì´ëŠ” node ë§Œë“¤ì. 

  - ë°ì´í„°ë¥¼ ë°›ê¸° ìœ„í•œ ì½”ë“œê°€ í•„ìš”í•˜ë‹¤ => `tf.placeholder`

- Weight (`W`) and Bias (`b`) ë¥¼ ë§¤ë²ˆ ë°”ê¿”ì£¼ì–´ì•¼í•¨. ê·¸ë¦¬ê³  ìµœì´ˆ `W`ì™€ `b`ëŠ” ë‚œìˆ˜ì´ë‹¤.

  - ë§¤ë²ˆ ë°”ê¾¸ê¸° ìœ„í•´ì„œ nodeë¥¼ ë³€ìˆ˜ë¡œ ì¡ì -> `tf.Variable()`
  - ë‚œìˆ˜ ì„¤ì •ì„ ìœ„í•´ `tf.random.normal()`ì´ë¼ëŠ” ë©”ì„œë“œë¥¼ ì´ìš©

- ê²°êµ­ ìš°ë¦¬ê°€ ì‚¬ìš©í•˜ê³ ì í•˜ëŠ” íšŒê·€ ì‹ì€ $ \hat{y} = w_1x_1 + w_2x_2 + w_3x_3 + b $ ì´ë‹¤. 

  ì´ê±¸ í–‰ë ¬ê³±ìœ¼ë¡œ í‘œí˜„í•´ë³´ë©´,  $ \hat{y} = XW + b $  ì´ë ‡ê²Œ ëœë‹¤.

  ì´ê±¸ `tensorflow`ë¡œ í‘œí˜„í•´ë³´ë©´:  `H = tf.matmul(X, W) + b` ì´ëŸ° ì‹ìœ¼ë¡œ í‘œí˜„ì´ë˜ëŠ” ì´ê²Œ ìš°ë¦¬ê°€ ì‚¬ìš©í•  ëª¨ë¸ì´ë‹¤.

- ì§€ë‚œë²ˆ íŒŒì´ì¬ìœ¼ë¡œ êµ¬í˜„í–ˆì„ë•Œì™€ ë§ˆì°¬ê°€ì§€ë¡œ `loss function`ì„¤ì •, í•™ìŠµì„ ì´ìš©í•œ `W`, `b` ì—…ë°ì´íŠ¸, ê·¸ë¦¬ê³  `tensorflow `ë§Œì˜ ê·¸ë˜í”„ë¥¼ ì‹¤í–‰ì‹œí‚¤ëŠ” `session` ì„¤ì • ë° ì‹¤í–‰, ë§ˆì§€ë§‰ìœ¼ë¡œ ë°˜ë³µí•™ìŠµì„ í•´ì£¼ë©´ ëœë‹¤. 

ì½”ë“œë¥¼ í†µí•´ í•´ë³´ì!

```python
######### 1. ì‹¤ì œ ë…ë¦½ë³€ìˆ˜ (X) ì™€ ì¢…ì†ë³€ìˆ˜ (T) ë¥¼ ì¶”ê°€í•˜ê¸° ìœ„í•œ node ìƒì„±

X = tf.placeholder(shape=[None,3], dtype=tf.float32) 
# ì»¬ëŸ¼ì˜ ê°œìˆ˜ëŠ” ê³ ì •. ë“¤ì–´ì˜¤ëŠ” í–‰ì˜ ê°œìˆ˜ëŠ” ìƒê´€í•˜ì§€ ì•ŠëŠ”ë‹¤.
# -1 ì˜ ì˜ë¯¸ë¥¼ ê°€ì§„ None ì´ë€ keywordë¥¼ ì‚¬ìš©.
# Noneì˜ ëœ»ì€ ì—†ë‹¤ê°€ ì•„ë‹˜. don't careì„. ë§ˆìŒëŒ€ë¡œ ë„£ì–´ë¼ ì„.
# ì¦‰ "rowëŠ” ì£¼ëŠ”ëŒ€ë¡œ ë°›ê² ë‹¤." ì´ì†Œë¦¬ì„

T = tf.placeholder(shape=[None,1], dtype=tf.float32)

######### 2. W and b ì„¤ì •
W = tf.Variable(tf.random.normal([3,1]), name='weight')  
# ë‚˜ì¤‘ì— ê°’ì„ ë°”ê¿€ ìˆ˜ ìˆëŠ” í…ì„œí”Œë¡œìš°ë§Œì˜ ë³€ìˆ˜.
# ë…ë¦½ ë³€ìˆ˜(X)ì˜ ì—´ì˜ í¬ê¸°ì™€ Wí–‰ì˜ í¬ê¸°ê°€ ê°™ì•„ì•¼í•¨.
# ì´ë¦„ì€ êµ³ì´ ì•ˆì¤˜ë„ ë¨. í•˜ì§€ë§Œ ì €ë ‡ê²Œ ì´ë¦„ì„ ì£¼ë©´ ì € ì´ë¦„ìœ¼ë¡œ ì‚¬ìš©ê°€ëŠ¥.
# tf.random  í…ì„œí”Œë¡œê°€ ê°–ê³  ìˆëŠ” ëœë¤ì¤‘ì—ì„œë„ normalì´ë¼ëŠ” ì •ê·œë¶„í¬ ì†ì„±ì„ ì´ìš©.
# np.randomê³¼ ë˜‘ê°™ìŒ
b = tf.Variable(tf.random.normal([1]), name='bias')

######### 3. hypothesis ì„¤ì •
H = tf.matmul(X, W) + b 

######### 4. loss function ì„¤ì •
loss = tf.reduce_mean(tf_square(H-T))    
# H - T  (ì˜ˆì¸¡ ë°ì´í„° - ì‹¤ì œ ë°ì´í„°) ì œê³±. ê·¸ë¦¬ê³  ê·¸ê±°ì— ëŒ€í•œ í‰ê· ê°’

######### 5. Gradient Descent Algorithmì„ í†µí•œ í•™ìŠµìœ¼ë¡œ W, b ì¬ì„¤ì •
train = tf.train.GradientDescentOptimizer(learning_rate=1e-4).minimize(loss)
# í˜„ì¬ Wì™€ bì—ì„œ í¸ë¯¸ë¶„ì„ í†µí•´ ì¡°ê¸ˆë” ë‚˜ì•„ì§„ Wì™€ bë¥¼ êµ¬í•˜ëŠ” ì‘ì—…ì„ í•´ì£¼ëŠ” nodeì„
# ëŸ¬ë‹ ë ˆì´íŠ¸ë¥¼ ì•Œë ¤ì¤˜ì„œ í¸ë¯¸ë¶„í•´ì„œ ì˜µí‹°ë§ˆì´ì¦ˆ í•˜ë¼ê³  ì§€ì‹œ
# ë˜ ë’¤ì— minimize(loss) ë¥¼ ë¶™ì—¬ì£¼ë¯€ë¡œì¨ ë¡œìŠ¤ê°’ì„ ìµœì†Œí™”

######### 6. session & ì´ˆê¸°í™”
sess = tf.Session()
sess.run(tf.global_variables_initializer())
# Variable ì‚¬ìš©ì‹œ ì´ˆê¸°í™” í•¨ìˆ˜ê°€ ê¼­ ë‚˜ì™€ì•¼ ì‘ë™ì„ í•œë‹¤.

######### 7. í•™ìŠµë…¸ë“œë¥¼ ì´ìš©í•˜ì—¬ ë°˜ë³µí•™ìŠµì„ ì§„í–‰í•˜ì!
for step in range(300000):
    tmp, loss_val = sess.run([train, loss], feed_dict={X: x_data, T: t_data})
    
    # ë…¸ë“œë¥¼ ì‹¤í–‰í•˜ë©´ ë…¸ë“œê°€ ê°€ì§„ ê°’ì´ ë‚˜ì˜´. ê·¸ë˜ì„œ tmpë¡œ ê·¸ ê°’ì„ ë°°ì •
    # ë…¸ë“œ ë‘ê°œë¥¼ ì‹¤í–‰. ê°ê° ë”°ë¡œë”°ë¡œ ì‹¤í–‰í•˜ëŠ”ê±°ì„.
    # train ê°’ì€ ì¤‘ìš”í•œê²Œ ì•„ë‹˜, W, b, loss ê°€ ì¤‘ìš”! ì—¬ê¸°ì„  lossê°’ë§Œ ë‚˜ì˜¨ë‹¤.
    if step % 30000 == 0:
        print("loss: {}".format(loss_val))
```

ì´ê±¸ ì´ì œ ì‹¤í–‰ì„ ì‹œí‚¤ë©´..!!!

```python
loss: 2.0639138221740723
loss: 0.0571671687066555
loss: 0.04494921490550041
loss: 0.038130346685647964
loss: 0.03406700864434242
loss: 0.03147490695118904
loss: 0.029711879789829254
loss: 0.028445681557059288
loss: 0.0274963341653347
loss: 0.02676238864660263
```

ì´ë ‡ê²Œ `loss`ê°’ì´ ìµœì†Œí™” ë˜ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤. ì—„ì²­ ë‚®ì€ ê°’ì€ ì•„ë‹ˆì§€ë§Œ.. ì¼ë‹¨ì€ ì§„í–‰í•˜ì

ì ì´ì œ í•™ìŠµì´ ëë‚¬ë‹¤. ê°’ì„ ì˜ˆì¸¡í•´ë³´ì

```python
# predictì„ í•´ë³´ì. 
# ì´ì   Hypothesisë¥¼ ì‹¤í–‰í•´ì•¼í•¨ => H node.
# H nodeë¥¼ ì‹¤í–‰í•˜ë ¤ë©´ X nodeì˜ placeholderì— ê°’ì„ ë„£ì–´ì¤˜ì•¼í•¨.
predict_data = np.array([[180.0, 10.0, 80.0]])  # [Solar.R  Wind  Temp]
scaled_predict_data = scaler_x.transform(predict_data)  # ê°’ì„ ë„£ì–´ì¤„ë•Œë„ ì •ê·œí™” ì‹œì¼œì„œ ë„£ì–´ì¤˜ì•¼í•¨

scaled_result = sess.run(H, feed_dict={X: scaled_predict_data})
# placeholderì— ê°’ì„ ë¶€ì—¬í•´ì„œ ì‹¤í–‰!!
result = scaler_y.inverse_transform(scaled_result.reshape(-1,1)) 
# ì •ê·œí™” ëœ ê°’ìœ¼ë¡œ ê²°ê³¼ê°€ íŠ€ì–´ë‚˜ì˜¤ë©´ inverse_transformì„ í†µí•´ì„œ ë‹¤ì‹œ ìŠ¤ì¼€ì¼ ì—…ì„ í•´ì£¼ì.

print(result)  # [[41.532608]]
```

`[[41.532608]]` ì´ë ‡ê²Œ ê²°ê³¼ê°€ ë‚˜ì™”ë‹¤. 

ì°¸ê³ ë¡œ `sklearn`ì—ì„œëŠ”`[[41.59545428]]` ì´ë¼ëŠ” ë¹„ìŠ·í•œ ê²°ê³¼ê°€ ë‚˜ì™”ë‹¤.

```python
###  sklearn ìœ¼ë¡œ êµ¬í˜„í•œ ì½”ë“œ
# Raw Data Loading
df = pd.read_csv('./data/ozone/ozone.csv', sep=',')
training_data_set = df[['Solar.R', 'Wind', 'Temp', 'Ozone']]

# 1. ê²°ì¹˜ê°’ ì²˜ë¦¬
training_data = training_data_set.dropna(how='any') 
# display(training_data.shape) # (111, 4)

# 2. ì´ìƒì¹˜ ì²˜ë¦¬
# ì§€ëŒ€ê°’ì€ ìš°ì„  ê·¸ëƒ¥ ë‘ì..
zscore_threshold = 1.8

outlier = training_data['Ozone'][ np.abs(stats.zscore(training_data['Ozone'])) > zscore_threshold ]  
training_data = training_data.loc[ ~training_data['Ozone'].isin(outlier), :]

x_data = training_data.iloc[:, :-1].values
t_data = training_data['Ozone'].values.reshape(-1,1)

model = linear_model.LinearRegression()
model.fit(x_data, t_data)
sklearn_result = model.predict([[180.0, 10.0, 80.0]])

print(sklearn_result)  # [[41.59545428]]
```

`sklearn`ì—ì„œëŠ” ìì²´ì ìœ¼ë¡œ ì •ê·œí™”ë¥¼ í•˜ê¸°ë•Œë¬¸ì— ë”°ë¡œ ì •ê·œí™” í•´ì„œ ë°ì´í„°ë¥¼ ë„˜ê²¨ì¤„ í•„ìš”ê°€ ì—†ë‹¤.

ì´ë²ˆ í¬ìŠ¤íŒ…ì—ì„  Multiple Linear Regressionì— ëŒ€í•´ì„œ ë°°ì›Œë³´ì•˜ë‹¤. ì´ íšŒê·€ë¶„ì„ ë°©ë²•ì€ ë¨¸ì‹ , ë”¥ëŸ¬ë‹ì˜ ê¸°ë³¸ì´ ëœë‹¤. ì˜ ìµí˜€ë‘ì.

ë§ˆì§€ë§‰ìœ¼ë¡œ `tensorflow`ê°€ ì–´ë–»ê²Œ ì‘ë™í•˜ëŠ”ì§€ ì•Œë ¤ì£¼ëŠ” ê·¸ë¦¼ì„ ì˜¬ë¦¬ë©°, ë”°ë¡œ ë¶€ê°€ì ì¸ ì„¤ëª… ì—†ì´ í¬ìŠ¤íŒ…ì„ ë§ˆë¬´ë¦¬í•˜ê² ë‹¤.

![tensorboard](/../assets/images/tf/tensorboard.png)

(ì¤‘ìš”í•œê±´ ì—£ì§€ì˜ í¬ì¸íŒ… ë°©í–¥!)

ì˜¤ëŠ˜ì˜ í¬ìŠ¤íŒ… ë„ìíŠ¸. ğŸ‘‹ 
